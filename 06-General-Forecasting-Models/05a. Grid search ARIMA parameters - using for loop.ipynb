{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [How to Grid Search ARIMA Model Hyperparameters with Python - For loop](https://machinelearningmastery.com/grid-search-arima-hyperparameters-with-python/)\n",
    "\n",
    "#### [endog, exog, what’s that?](https://www.statsmodels.org/stable/endog_exog.html)\n",
    "\n",
    "#### [How to Make Out-of-Sample Forecasts with ARIMA in Python](https://machinelearningmastery.com/make-sample-forecasts-arima-python/)\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "- A general procedure that you can use to tune the ARIMA hyperparameters for a rolling one-step forecast.\n",
    "- How to apply ARIMA hyperparameter optimization on a standard univariate time series dataset.\n",
    "- Ideas for extending the procedure for more elaborate and robust models.\n",
    "\n",
    "#### Grid Searching Method\n",
    "\n",
    "We can automate the process of training and evaluating ARIMA models on different combinations of model hyperparameters. In machine learning this is called a grid search or model tuning.\n",
    "\n",
    "In this tutorial, we will develop a method to grid search ARIMA hyperparameters for a one-step rolling forecast.\n",
    "\n",
    "The approach is broken down into two parts:\n",
    "\n",
    "1. Evaluate an ARIMA model.\n",
    "2. Evaluate sets of ARIMA parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Evaluate an ARIMA model\n",
    "\n",
    "We can evaluate an ARIMA model by preparing it on a training dataset and evaluating predictions on a test dataset.\n",
    "\n",
    "This approach involves the following steps:\n",
    "\n",
    "1. Split the dataset into training and test sets.\n",
    "2. Walk the time steps in the test dataset.\n",
    "        a. Train an ARIMA model.\n",
    "        b. Make a one-step prediction.\n",
    "        c. Store prediction; get and store actual observation.\n",
    "3. Calculate error score for predictions compared to expected values.\n",
    "\n",
    "We can implement this in Python as a new standalone function called `evaluate_arima_model()` that takes a time series dataset as input as well as a tuple with the p, d, and q parameters for the model to be evaluated.\n",
    "\n",
    "The dataset is split in two: 66% for the initial training dataset and the remaining 34% for the test dataset.\n",
    "\n",
    "Each time step of the test set is iterated. Just one iteration provides a model that you could use to make predictions on new data. The iterative approach allows a new ARIMA model to be trained each time step.\n",
    "\n",
    "A prediction is made each iteration and stored in a list. This is so that at the end of the test set, all predictions can be compared to the list of expected values and an error score calculated. In this case, a mean squared error score is calculated and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "# Load specific forecasting tools\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "def evaluate_arima_models(X, arima_order):\n",
    "    # prepare training datasets\n",
    "    train_size = int(len(X)*0.66)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions =  list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, arima_order)\n",
    "        model_fit = model.fit()\n",
    "        yhat = model_fit.forecast()[0][0] # one-step out-of sample forecast\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "    # calculate rmse\n",
    "    error = rmse(test, predictions)\n",
    "    return(error)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Iterate ARIMA parameters\n",
    "\n",
    "The user must specify a grid of p, d, and q ARIMA parameters to iterate. A model is created for each parameter and its performance evaluated by calling the `evaluate_arima_model()` function described in the previous section.\n",
    "\n",
    "The function must keep track of the lowest error score observed and the configuration that caused it. This can be summarized at the end of the function with a print to standard out.\n",
    "\n",
    "We can implement this function called `evaluate_models()` as a series of four loops.\n",
    "\n",
    "There are two additional considerations. The first is to ensure the input data are floating point values (as opposed to integers or strings), as this can cause the ARIMA procedure to fail.\n",
    "\n",
    "Second, the statsmodels ARIMA procedure internally uses numerical optimization procedures to find a set of coefficients for the model. These procedures can fail, which in turn can throw an exception. We must catch these exceptions and skip those configurations that cause a problem. This happens more often then you would think.\n",
    "\n",
    "Additionally, it is recommended that warnings be ignored for this code to avoid a lot of noise from running the procedure. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete procedure for evaluating a grid of ARIMA hyperparameters is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate combinations of p,d,q values for an ARIMA model\n",
    "\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "    dataset = dataset.astype('float32')\n",
    "    best_score, best_cfg = float('inf'), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    rmse = evaluate_arima_models(dataset, order)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, order\n",
    "                        print(\"ARIMA order: %s and RMSE = %.3f\" % (order,rmse))\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "    print(\"Best ARIMA order %s and RMSE = %.3f\"%(best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a procedure to grid search ARIMA hyperparameters, let’s test the procedure on two univariate time series problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1901-01-01</th>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901-02-01</th>\n",
       "      <td>145.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901-03-01</th>\n",
       "      <td>183.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901-04-01</th>\n",
       "      <td>119.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901-05-01</th>\n",
       "      <td>180.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "Month            \n",
       "1901-01-01  266.0\n",
       "1901-02-01  145.9\n",
       "1901-03-01  183.1\n",
       "1901-04-01  119.3\n",
       "1901-05-01  180.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def parser(x):\n",
    "    return(datetime.strptime('190'+x, '%Y-%m'))\n",
    "\n",
    "df = pd.read_csv('../Data/shampoo.csv', header = 0, parse_dates = [0], index_col = 0, date_parser = parser)\n",
    "df.index.freq = 'MS'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loaded, we can specify a site of p, d, and q values to search and pass them to the `evaluate_models()` function.\n",
    "\n",
    "We will try a suite of lag values (p) and just a few difference iterations (d) and residual error lag values (q)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = [0, 1, 2, 4, 6, 8]\n",
    "d_values = range(0,3)\n",
    "q_vales = range(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0)\n",
      "ARIMA order: (0, 0, 0) and RMSE = 52425.268\n",
      "(0, 0, 1)\n",
      "ARIMA order: (0, 0, 1) and RMSE = 38145.141\n",
      "(0, 0, 2)\n",
      "ARIMA order: (0, 0, 2) and RMSE = 23989.607\n",
      "(0, 0, 3)\n",
      "(0, 0, 4)\n",
      "(0, 1, 0)\n",
      "ARIMA order: (0, 1, 0) and RMSE = 18003.173\n",
      "(0, 1, 1)\n",
      "ARIMA order: (0, 1, 1) and RMSE = 9558.246\n",
      "(0, 1, 2)\n",
      "ARIMA order: (0, 1, 2) and RMSE = 6306.315\n",
      "(0, 1, 3)\n",
      "(0, 1, 4)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(0, 2, 3)\n",
      "ARIMA order: (0, 2, 3) and RMSE = 3935.567\n",
      "(0, 2, 4)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 0, 3)\n",
      "(1, 0, 4)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 1, 3)\n",
      "(1, 1, 4)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(1, 2, 3)\n",
      "(1, 2, 4)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 0, 3)\n",
      "(2, 0, 4)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 1, 3)\n",
      "(2, 1, 4)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "(2, 2, 3)\n",
      "(2, 2, 4)\n",
      "(4, 0, 0)\n",
      "(4, 0, 1)\n",
      "(4, 0, 2)\n",
      "(4, 0, 3)\n",
      "(4, 0, 4)\n",
      "(4, 1, 0)\n",
      "(4, 1, 1)\n",
      "(4, 1, 2)\n",
      "(4, 1, 3)\n",
      "(4, 1, 4)\n",
      "(4, 2, 0)\n",
      "(4, 2, 1)\n",
      "(4, 2, 2)\n",
      "(4, 2, 3)\n",
      "(4, 2, 4)\n",
      "(6, 0, 0)\n",
      "(6, 0, 1)\n",
      "(6, 0, 2)\n",
      "(6, 0, 3)\n",
      "(6, 0, 4)\n",
      "(6, 1, 0)\n",
      "(6, 1, 1)\n",
      "(6, 1, 2)\n",
      "(6, 1, 3)\n",
      "(6, 1, 4)\n",
      "(6, 2, 0)\n",
      "(6, 2, 1)\n",
      "(6, 2, 2)\n",
      "(6, 2, 3)\n",
      "(6, 2, 4)\n",
      "(8, 0, 0)\n",
      "(8, 0, 1)\n",
      "(8, 0, 2)\n",
      "(8, 0, 3)\n",
      "(8, 0, 4)\n",
      "(8, 1, 0)\n",
      "(8, 1, 1)\n",
      "(8, 1, 2)\n",
      "(8, 1, 3)\n",
      "(8, 1, 4)\n",
      "(8, 2, 0)\n",
      "(8, 2, 1)\n",
      "(8, 2, 2)\n",
      "(8, 2, 3)\n",
      "(8, 2, 4)\n",
      "Best ARIMA order (0, 2, 3) and RMSE = 62.734\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(df['Sales'], p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Births</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959-01-01</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-01-02</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-01-03</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-01-04</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-01-05</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Births\n",
       "Date              \n",
       "1959-01-01      35\n",
       "1959-01-02      32\n",
       "1959-01-03      30\n",
       "1959-01-04      31\n",
       "1959-01-05      44"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('../Data/DailyTotalFemaleBirths.csv',index_col='Date',parse_dates=True)\n",
    "df2.index.freq = 'D'\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = [0, 1, 2, 4, 6, 8, 10]\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA order: (0, 0, 0) and RMSE = 8.189\n",
      "ARIMA order: (0, 0, 1) and RMSE = 7.884\n",
      "ARIMA order: (0, 0, 2) and RMSE = 7.771\n",
      "ARIMA order: (0, 1, 1) and RMSE = 7.527\n",
      "ARIMA order: (0, 1, 2) and RMSE = 7.434\n",
      "ARIMA order: (1, 1, 1) and RMSE = 7.425\n",
      "ARIMA order: (2, 0, 1) and RMSE = 7.421\n",
      "ARIMA order: (2, 1, 1) and RMSE = 7.417\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(df2['Births'], p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extensions\n",
    "\n",
    "This section lists some ideas to extend the approach you may wish to explore.\n",
    "\n",
    "1. __Seed Grid__. The classical diagnostic tools of ACF and PACF plots can still be used with the results used to seed the grid of ARIMA parameters to search.\n",
    "2. __Alternate Measures__. The search seeks to optimize the out-of-sample mean squared error. This could be changed to another out-of-sample statistic, an in-sample statistic, such as AIC or BIC, or some combination of the two. You can choose a metric that is most meaningful on your project.\n",
    "3. __Residual Diagnostics__. Statistics can automatically be calculated on the residual forecast errors to provide an additional indication of the quality of the fit. Examples include statistical tests for whether the distribution of residuals is Gaussian and whether there is an autocorrelation in the residuals.\n",
    "4. __Update Model__. The ARIMA model is created from scratch for each one-step forecast. With careful inspection of the API, it may be possible to update the internal data of the model with new observations rather than recreating it from scratch.\n",
    "5. __Preconditions__. The ARIMA model can make assumptions about the time series dataset, such as normality and stationarity. These could be checked and a warning raised for a given of a dataset prior to a given model being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
